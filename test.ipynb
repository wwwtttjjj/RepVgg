{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 48, 112, 112]           1,344\n",
      "          Identity-2         [-1, 48, 112, 112]               0\n",
      "              ReLU-3         [-1, 48, 112, 112]               0\n",
      "       RepVggblock-4         [-1, 48, 112, 112]               0\n",
      "            Conv2d-5           [-1, 48, 56, 56]          20,784\n",
      "          Identity-6           [-1, 48, 56, 56]               0\n",
      "              ReLU-7           [-1, 48, 56, 56]               0\n",
      "       RepVggblock-8           [-1, 48, 56, 56]               0\n",
      "            Conv2d-9           [-1, 48, 56, 56]          20,784\n",
      "         Identity-10           [-1, 48, 56, 56]               0\n",
      "             ReLU-11           [-1, 48, 56, 56]               0\n",
      "      RepVggblock-12           [-1, 48, 56, 56]               0\n",
      "           Conv2d-13           [-1, 96, 28, 28]          41,568\n",
      "         Identity-14           [-1, 96, 28, 28]               0\n",
      "             ReLU-15           [-1, 96, 28, 28]               0\n",
      "      RepVggblock-16           [-1, 96, 28, 28]               0\n",
      "           Conv2d-17           [-1, 96, 28, 28]          83,040\n",
      "         Identity-18           [-1, 96, 28, 28]               0\n",
      "             ReLU-19           [-1, 96, 28, 28]               0\n",
      "      RepVggblock-20           [-1, 96, 28, 28]               0\n",
      "           Conv2d-21           [-1, 96, 28, 28]          83,040\n",
      "         Identity-22           [-1, 96, 28, 28]               0\n",
      "             ReLU-23           [-1, 96, 28, 28]               0\n",
      "      RepVggblock-24           [-1, 96, 28, 28]               0\n",
      "           Conv2d-25           [-1, 96, 28, 28]          83,040\n",
      "         Identity-26           [-1, 96, 28, 28]               0\n",
      "             ReLU-27           [-1, 96, 28, 28]               0\n",
      "      RepVggblock-28           [-1, 96, 28, 28]               0\n",
      "           Conv2d-29          [-1, 192, 14, 14]         166,080\n",
      "         Identity-30          [-1, 192, 14, 14]               0\n",
      "             ReLU-31          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-32          [-1, 192, 14, 14]               0\n",
      "           Conv2d-33          [-1, 192, 14, 14]         331,968\n",
      "         Identity-34          [-1, 192, 14, 14]               0\n",
      "             ReLU-35          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-36          [-1, 192, 14, 14]               0\n",
      "           Conv2d-37          [-1, 192, 14, 14]         331,968\n",
      "         Identity-38          [-1, 192, 14, 14]               0\n",
      "             ReLU-39          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-40          [-1, 192, 14, 14]               0\n",
      "           Conv2d-41          [-1, 192, 14, 14]         331,968\n",
      "         Identity-42          [-1, 192, 14, 14]               0\n",
      "             ReLU-43          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-44          [-1, 192, 14, 14]               0\n",
      "           Conv2d-45          [-1, 192, 14, 14]         331,968\n",
      "         Identity-46          [-1, 192, 14, 14]               0\n",
      "             ReLU-47          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-48          [-1, 192, 14, 14]               0\n",
      "           Conv2d-49          [-1, 192, 14, 14]         331,968\n",
      "         Identity-50          [-1, 192, 14, 14]               0\n",
      "             ReLU-51          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-52          [-1, 192, 14, 14]               0\n",
      "           Conv2d-53          [-1, 192, 14, 14]         331,968\n",
      "         Identity-54          [-1, 192, 14, 14]               0\n",
      "             ReLU-55          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-56          [-1, 192, 14, 14]               0\n",
      "           Conv2d-57          [-1, 192, 14, 14]         331,968\n",
      "         Identity-58          [-1, 192, 14, 14]               0\n",
      "             ReLU-59          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61          [-1, 192, 14, 14]         331,968\n",
      "         Identity-62          [-1, 192, 14, 14]               0\n",
      "             ReLU-63          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-64          [-1, 192, 14, 14]               0\n",
      "           Conv2d-65          [-1, 192, 14, 14]         331,968\n",
      "         Identity-66          [-1, 192, 14, 14]               0\n",
      "             ReLU-67          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-68          [-1, 192, 14, 14]               0\n",
      "           Conv2d-69          [-1, 192, 14, 14]         331,968\n",
      "         Identity-70          [-1, 192, 14, 14]               0\n",
      "             ReLU-71          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-72          [-1, 192, 14, 14]               0\n",
      "           Conv2d-73          [-1, 192, 14, 14]         331,968\n",
      "         Identity-74          [-1, 192, 14, 14]               0\n",
      "             ReLU-75          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-76          [-1, 192, 14, 14]               0\n",
      "           Conv2d-77          [-1, 192, 14, 14]         331,968\n",
      "         Identity-78          [-1, 192, 14, 14]               0\n",
      "             ReLU-79          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-80          [-1, 192, 14, 14]               0\n",
      "           Conv2d-81          [-1, 192, 14, 14]         331,968\n",
      "         Identity-82          [-1, 192, 14, 14]               0\n",
      "             ReLU-83          [-1, 192, 14, 14]               0\n",
      "      RepVggblock-84          [-1, 192, 14, 14]               0\n",
      "           Conv2d-85           [-1, 1280, 7, 7]       2,213,120\n",
      "         Identity-86           [-1, 1280, 7, 7]               0\n",
      "             ReLU-87           [-1, 1280, 7, 7]               0\n",
      "      RepVggblock-88           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-89           [-1, 1280, 1, 1]               0\n",
      "           Linear-90                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 8,309,384\n",
      "Trainable params: 8,309,384\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 54.76\n",
      "Params size (MB): 31.70\n",
      "Estimated Total Size (MB): 87.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import model\n",
    "from torchsummary import summary\n",
    "mod = model.get_RepVgg_func_by_name('RepVgg-A0')().cuda()\n",
    "\n",
    "x = torch.randn((1,3,224,224)).cuda()\n",
    "mod = model.repVgg_model_convert(mod)\n",
    "print(summary(mod, input_size=(3,224,224)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7748/2508364927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_load\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0my_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelRepVgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0my_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0my_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\deep_learing_work\\all_work\\RepVgg\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\deep_learing_work\\all_work\\RepVgg\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0midout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbr_idenity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbr_1x1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbr_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0midout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     '''\n\u001b[0;32m     57\u001b[0m     \u001b[0mdont\u001b[0m \u001b[0mkonw\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mmean\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2419\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2421\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2422\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import imp\n",
    "from re import A\n",
    "from cv2 import transform\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import model\n",
    "import wandb\n",
    "\n",
    "batch_size = 8\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "'''\n",
    "data\n",
    "'''\n",
    "train_root = \"D:/deep_learing_work/data/cif10/train/raw-img\"\n",
    "test_root = \"D:/deep_learing_work/data/cif10/test/raw-img\"\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean = [0.485, 0.456,0.406],std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "data_iter = torchvision.datasets.ImageFolder(root=train_root, transform=transform)\n",
    "data_load = torch.utils.data.DataLoader(data_iter, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_iter = torchvision.datasets.ImageFolder(root=test_root, transform=transform)\n",
    "test_load = torch.utils.data.DataLoader(test_iter, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "epochs = 20\n",
    "lossf = torch.nn.CrossEntropyLoss()\n",
    "lr = 1e-5\n",
    "# wandb.init(entity='wtj', project='Repvgg object classifier')\n",
    "# wandb.config = {\n",
    "#     'lr':0.0001,\n",
    "#     'epochs':20, \n",
    "#     'batch_size':8\n",
    "# }\n",
    "\n",
    "modelRepVgg = model.get_RepVgg_func_by_name('RepVgg-A0')(num_classes = 10).to(device)\n",
    "modelRepVgg.train()\n",
    "optimizer = torch.optim.SGD(modelRepVgg.parameters(), lr = lr)\n",
    "\n",
    "for eopch in range(epochs):\n",
    "    loss_arr = []\n",
    "    for x_cpu, y_cpu in data_load:\n",
    "        optimizer.zero_grad()\n",
    "        x = x_cpu.to(device)\n",
    "        y = y_cpu.to(device)\n",
    "        y_p = modelRepVgg(x)\n",
    "        train_loss = lossf(y_p, y).sum()\n",
    "        train_loss.backward()\n",
    "        loss_arr.append(train_loss.detach().cpu())\n",
    "        optimizer.step()\n",
    "    modelRepVgg.eval()\n",
    "    with torch.no_grad():\n",
    "        train_mean_loss = torch.tensor(loss_arr)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, y in test_load:\n",
    "            x, y = x.to(device),y.to(device)\n",
    "            y_p = modelRepVgg(x)\n",
    "            y_p = y_p.cpu()\n",
    "            y_p = torch.argmax(y_p, dim = 1)\n",
    "            label = y.cpu()\n",
    "            correct +=  (y_p == label).sum()\n",
    "            total += batch_size\n",
    "        test_acc = correct / total\n",
    "        wandb.log({'train_loss':train_mean_loss,'test_acc:':test_acc})    \n",
    "    modelRepVgg.train()\n",
    "    model.save(modelRepVgg, './RepVgg.pt')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd20d70289efe81e12b0415a912ee7b2c702a145bbd8130b01157319f05c9307"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
